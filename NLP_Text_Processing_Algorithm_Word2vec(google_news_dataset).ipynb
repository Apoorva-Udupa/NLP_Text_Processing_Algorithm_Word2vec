{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzj7bruSd7xD",
        "outputId": "fccc4c35-e8ca-4eb9-e05e-4e9c971b1cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z3snLKSxi2YF"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gj7-rUC0eAjK"
      },
      "outputs": [],
      "source": [
        "Corpus=\"\"\"Hello my name is Apoorva and,I am studying at UIUC. I focus on technologies like natural languge processing,machine learning,artificial intelligence among others.\n",
        "I aspire to be one of the very technical resercher in a top MNC in the future and ,help the organization with my skills and acumen\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vGbwFvFg2Yg",
        "outputId": "ccdefd56-4209-4604-80a8-4ece519f8871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Apoorva and,I am studying at UIUC. I focus on technologies like natural languge processing,machine learning,artificial intelligence among others.\n",
            "I aspire to be one of the very technical resercher in a top MNC in the future and ,help the organization with my skills and acumen\n"
          ]
        }
      ],
      "source": [
        "print(Corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ISxQ3z8Dg5K8"
      },
      "outputs": [],
      "source": [
        "#Tokenization\n",
        "#Converting Sentence --->paragraphs\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk4UPcZVieN1",
        "outputId": "39c64d42-fd88-4f9c-86e1-597b77f590fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UzePiihShqgA"
      },
      "outputs": [],
      "source": [
        "documents=sent_tokenize(Corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY5Cy28Uj8Y3",
        "outputId": "5ffa7bc2-0814-4ff5-9e6e-9c3cf82f44b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbaBJnN5jj1q",
        "outputId": "18b326ec-b993-4c82-f453-26d1bb1f7bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Apoorva and,I am studying at UIUC.\n",
            "I focus on technologies like natural languge processing,machine learning,artificial intelligence among others.\n",
            "I aspire to be one of the very technical resercher in a top MNC in the future and ,help the organization with my skills and acumen\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FyF3C-A3kE_1"
      },
      "outputs": [],
      "source": [
        "##Tokenization\n",
        "#paragraph----->words\n",
        "#sentence------>words\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTG3KVyfkcPI",
        "outputId": "ca9f3e27-316a-471c-bec1-a74d82f6ade8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'my',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Apoorva',\n",
              " 'and',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'studying',\n",
              " 'at',\n",
              " 'UIUC',\n",
              " '.',\n",
              " 'I',\n",
              " 'focus',\n",
              " 'on',\n",
              " 'technologies',\n",
              " 'like',\n",
              " 'natural',\n",
              " 'languge',\n",
              " 'processing',\n",
              " ',',\n",
              " 'machine',\n",
              " 'learning',\n",
              " ',',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'among',\n",
              " 'others',\n",
              " '.',\n",
              " 'I',\n",
              " 'aspire',\n",
              " 'to',\n",
              " 'be',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'very',\n",
              " 'technical',\n",
              " 'resercher',\n",
              " 'in',\n",
              " 'a',\n",
              " 'top',\n",
              " 'MNC',\n",
              " 'in',\n",
              " 'the',\n",
              " 'future',\n",
              " 'and',\n",
              " ',',\n",
              " 'help',\n",
              " 'the',\n",
              " 'organization',\n",
              " 'with',\n",
              " 'my',\n",
              " 'skills',\n",
              " 'and',\n",
              " 'acumen']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "word_tokenize(Corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8dvXL-DkwYB",
        "outputId": "9072fd29-a663-4c99-995a-fba1ae244221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'my', 'name', 'is', 'Apoorva', 'and', ',', 'I', 'am', 'studying', 'at', 'UIUC', '.']\n",
            "['I', 'focus', 'on', 'technologies', 'like', 'natural', 'languge', 'processing', ',', 'machine', 'learning', ',', 'artificial', 'intelligence', 'among', 'others', '.']\n",
            "['I', 'aspire', 'to', 'be', 'one', 'of', 'the', 'very', 'technical', 'resercher', 'in', 'a', 'top', 'MNC', 'in', 'the', 'future', 'and', ',', 'help', 'the', 'organization', 'with', 'my', 'skills', 'and', 'acumen']\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "  print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jGcBJOyelEeW"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NIl37W2lbii",
        "outputId": "329d2101-12cf-49c1-cf93-4b3902635f12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'my',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Apoorva',\n",
              " 'and',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'studying',\n",
              " 'at',\n",
              " 'UIUC',\n",
              " '.',\n",
              " 'I',\n",
              " 'focus',\n",
              " 'on',\n",
              " 'technologies',\n",
              " 'like',\n",
              " 'natural',\n",
              " 'languge',\n",
              " 'processing',\n",
              " ',',\n",
              " 'machine',\n",
              " 'learning',\n",
              " ',',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'among',\n",
              " 'others',\n",
              " '.',\n",
              " 'I',\n",
              " 'aspire',\n",
              " 'to',\n",
              " 'be',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'very',\n",
              " 'technical',\n",
              " 'resercher',\n",
              " 'in',\n",
              " 'a',\n",
              " 'top',\n",
              " 'MNC',\n",
              " 'in',\n",
              " 'the',\n",
              " 'future',\n",
              " 'and',\n",
              " ',',\n",
              " 'help',\n",
              " 'the',\n",
              " 'organization',\n",
              " 'with',\n",
              " 'my',\n",
              " 'skills',\n",
              " 'and',\n",
              " 'acumen']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#so that the punctuation is treated as a separate word\n",
        "wordpunct_tokenize(Corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a6pTFlFelyQA"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f4TdKNCuljZR"
      },
      "outputs": [],
      "source": [
        "tokenizer=TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15up6S6EmHno",
        "outputId": "c74194fe-ad11-483a-ec88-78a23b104bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'my',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Apoorva',\n",
              " 'and',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'studying',\n",
              " 'at',\n",
              " 'UIUC.',\n",
              " 'I',\n",
              " 'focus',\n",
              " 'on',\n",
              " 'technologies',\n",
              " 'like',\n",
              " 'natural',\n",
              " 'languge',\n",
              " 'processing',\n",
              " ',',\n",
              " 'machine',\n",
              " 'learning',\n",
              " ',',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'among',\n",
              " 'others.',\n",
              " 'I',\n",
              " 'aspire',\n",
              " 'to',\n",
              " 'be',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'very',\n",
              " 'technical',\n",
              " 'resercher',\n",
              " 'in',\n",
              " 'a',\n",
              " 'top',\n",
              " 'MNC',\n",
              " 'in',\n",
              " 'the',\n",
              " 'future',\n",
              " 'and',\n",
              " ',',\n",
              " 'help',\n",
              " 'the',\n",
              " 'organization',\n",
              " 'with',\n",
              " 'my',\n",
              " 'skills',\n",
              " 'and',\n",
              " 'acumen']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#full stop is no longer treated as a separate word after this\n",
        "tokenizer.tokenize(Corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2E7wjQhmleK"
      },
      "source": [
        "##Text Preprocessing\n",
        "\n",
        "#Stemming\n",
        "stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known known as a lemma.Stemming is imp in NLU and NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WSFyzSuynKys"
      },
      "outputs": [],
      "source": [
        "#if we are solving a classification problem\n",
        "#comments of the product is a positive review or negative review\n",
        "##Review-------->eating,eat,eaten(are the same)[going,goes,go,gone]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IRhAlTFQnu75"
      },
      "outputs": [],
      "source": [
        "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-GERcD9oTLI"
      },
      "source": [
        "###***Porter Stemmer***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f13lx2Oaog_y"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-tboUC9Lq3hU"
      },
      "outputs": [],
      "source": [
        "stemming=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsUbqcFvq9Xd",
        "outputId": "1b3f77cf-8e74-46a2-d90b-2c7f793e233e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word+\"---->\"+stemming.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj6kaIKur7JD"
      },
      "source": [
        "##Some major disadvantage of stemming as we see from above is **history---->histori **the meaning of the word entirely changed ,where as we can see it being classified into correct root word we also see some gaps with stemming\n",
        "\n",
        "This finds its use in email classification into spam or ham"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yfBHVT9Cr0rS",
        "outputId": "35b708e6-7daa-4e22-f7a3-3132e3eb9ac5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'congratul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "stemming.stem('congratulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WZO593ajtxuB",
        "outputId": "bd1354be-c5b4-46f0-bce3-2889649b6858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "stemming.stem('sitting')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRGCqnsns4K7"
      },
      "source": [
        "###REGEX Stemmer Class\n",
        "##NLTK has regexstemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms.It basically takes a single regular expression and removes any prefix or suffix that matches the expression.Let us see an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Om4IBxLUsd1B"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import RegexpStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u8FDCfOpuC9J"
      },
      "outputs": [],
      "source": [
        "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$',min=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZSnMYXH8vHZ-",
        "outputId": "33232d0a-39bb-43d5-ebee-8dc0be837eea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "reg_stemmer.stem('eating')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8WJiQyovCsT"
      },
      "source": [
        "##Snowball Stemmer\n",
        "better than Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UDz5s6ZfvCSM"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "U_PXy8JEuqrS"
      },
      "outputs": [],
      "source": [
        "snowballstemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddn0GyTTuyGz",
        "outputId": "6bdc3895-c22c-4c34-84bc-0b32e9f24a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating------->eat\n",
            "eats------->eat\n",
            "eaten------->eaten\n",
            "writing------->write\n",
            "writes------->write\n",
            "programming------->program\n",
            "programs------->program\n",
            "history------->histori\n",
            "finally------->final\n",
            "finalized------->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word+\"------->\"+snowballstemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVKIDsgYwon4"
      },
      "source": [
        "##Where snowball stemmer outperforms porter stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_olqW82w4EK",
        "outputId": "caccfa07-9d30-4141-cad5-3b1634520a8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairli', 'sportingli')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M4yVXz0xDBn",
        "outputId": "f28c61ad-8945-460b-f604-b0364e2c5238"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl6geey5xf-5"
      },
      "source": [
        "###Text Processing-**Lemmatization**\n",
        "##The stemming techniques cannot be used for chatbots instead we can use the lemmatization technique\n",
        "\n",
        "###Wordnet Lemmetizer\n",
        "Lemmatization is like stemming.The output we will get after lemmatization is called \"lemma\",which is a root word rather than root stem,the output of stemming.After Lemmatization,we will be getting a valid word that means the same thing.\n",
        "\n",
        "NLTK package has WordNetLemmatizer class which is a thin wrapper around the wordnet Corpus.This class uses morphy() function to the WordNet CorpusReader class to find lemma.Let us understand it with an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWgsf2_BxQgN",
        "outputId": "de1220ed-0e28-454b-df74-c761ba2e00e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "E1CzBI1tGRhi"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9Aqhb2vjFjbk"
      },
      "outputs": [],
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "acMMyKKWFr80",
        "outputId": "813f14ae-b73e-4c1c-d210-263eee0fe6c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'going'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "'''\n",
        "POS-Noun-n\n",
        "verb-v\n",
        "adjective-a\n",
        "adverb-r\n",
        "'''\n",
        "lemmatizer.lemmatize(\"going\",pos='n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yz5a9_3VGy0A",
        "outputId": "532b0793-2863-4ad3-dc60-e962823c4b24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"going\",pos='v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Brzh-OG4bt",
        "outputId": "dfdd2fea-c115-4de0-8098-209c57623dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating------->eat\n",
            "eats------->eat\n",
            "eaten------->eat\n",
            "writing------->write\n",
            "writes------->write\n",
            "programming------->program\n",
            "programs------->program\n",
            "history------->history\n",
            "finally------->finally\n",
            "finalized------->finalize\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word+\"------->\"+lemmatizer.lemmatize(word,pos='v'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXR8vdaPHexO"
      },
      "source": [
        "#Lemmatizer takes longer than stemming\n",
        "##It can be used in Q and A chatbot text summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94rFmLo_H5S2"
      },
      "source": [
        "##Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2WYDmsr4HJGt"
      },
      "outputs": [],
      "source": [
        "paragraph='''A middle child, Martin Jr. had an older sister, Willie, and a younger brother, Alfred. The King children grew up in a secure and loving environment. Martin Sr. was more the disciplinarian, while Alberta’s gentleness easily balanced out their father’s strict hand.\n",
        "\n",
        "Although they undoubtedly tried, Martin Jr.’s parents couldn’t shield him completely from racism. His father fought against racial prejudice, not just because his race suffered, but also because he considered racism and segregation to be an affront to God’s will. He strongly discouraged any sense of class superiority in his children, which left a lasting impression on Martin Jr.\n",
        "\n",
        "Growing up in Atlanta, King entered public school at age 5. In May 1936, he was baptized, but the event made little impression on him.\n",
        "\n",
        "In May 1941, King was 12 years old when his grandmother Jennie died of a heart attack. The event was traumatic for the boy, more so because he was out watching a parade against his parents’ wishes when she died. Distraught at the news, young King jumped from a second-story window at the family home, allegedly attempting suicide.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Zpolb25dIZ2h"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n12HBQfOIsUm",
        "outputId": "75784ded-6cd2-4948-8adf-be8749950bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62n5w1V0Ix9C",
        "outputId": "104e09ac-dcdf-4aa6-e8d0-9379ed3d24ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X46jiUaJrFD",
        "outputId": "d9ea3876-d448-4408-ebbe-0eaac76dc639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK resources if they aren't already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DolqwbfuJ87_"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))  # Initialize the set of English stopwords\n",
        "stemmer = PorterStemmer()  # Initialize the Porter Stemmer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "CuQH04PlJJ6q"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "c86ezlCrJUh8"
      },
      "outputs": [],
      "source": [
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    filtered_words = [stemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
        "    sentences[i] = ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jUdEFbBKGse",
        "outputId": "83e8e436-94ef-479c-c8fa-7f4d30d441e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "middl child , martin jr. older sister , willi , younger brother , alfr .\n",
            "king children grew secur love environ .\n",
            "martin sr. disciplinarian , alberta ’ gentl easili balanc father ’ strict hand .\n",
            "although undoubtedli tri , martin jr. ’ parent ’ shield complet racism .\n",
            "father fought racial prejudic , race suffer , also consid racism segreg affront god ’ .\n",
            "strongli discourag sens class superior children , left last impress martin jr .\n",
            "grow atlanta , king enter public school age 5 .\n",
            "may 1936 , baptiz , event made littl impress .\n",
            "may 1941 , king 12 year old grandmoth jenni die heart attack .\n",
            "event traumat boy , watch parad parent ’ wish die .\n",
            "distraught news , young king jump second-stori window famili home , allegedli attempt suicid .\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U1UCxCREN-Nb"
      },
      "outputs": [],
      "source": [
        "Snowballstemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "PhHVKQSaOI-I"
      },
      "outputs": [],
      "source": [
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    filtered_words = [snowballstemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
        "    sentences[i] = ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R2VSssLOUmT",
        "outputId": "718bf557-1283-45df-ef87-69ee80c56e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "middl child , martin jr. older sister , willi , younger brother , alfr .\n",
            "king children grew secur love environ .\n",
            "martin sr. disciplinarian , alberta ’ gentl easili balanc father ’ strict hand .\n",
            "although undoubted tri , martin jr. ’ parent ’ shield complet racism .\n",
            "father fought racial prejud , race suffer , also consid racism segreg affront god ’ .\n",
            "strong discourag sen class superior children , left last impress martin jr .\n",
            "grow atlanta , king enter public school age 5 .\n",
            "may 1936 , baptiz , event made littl impress .\n",
            "may 1941 , king 12 year old grandmoth jenni die heart attack .\n",
            "event traumat boy , watch parad parent ’ wish die .\n",
            "distraught news , young king jump second-stori window famili home , alleged attempt suicid .\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b6D9lCCAOmU3"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "K5DjQS83OdEh"
      },
      "outputs": [],
      "source": [
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
        "    sentences[i] = ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyY7NY4gOxIa",
        "outputId": "08d47b3d-8f6a-436f-ebe5-5c8bb94f1f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "middle child , Martin Jr. older sister , Willie , younger brother , Alfred .\n",
            "King child grew secure loving environment .\n",
            "Martin Sr. disciplinarian , Alberta ’ gentleness easily balanced father ’ strict hand .\n",
            "Although undoubtedly tried , Martin Jr. ’ parent ’ shield completely racism .\n",
            "father fought racial prejudice , race suffered , also considered racism segregation affront God ’ .\n",
            "strongly discouraged sense class superiority child , left lasting impression Martin Jr .\n",
            "Growing Atlanta , King entered public school age 5 .\n",
            "May 1936 , baptized , event made little impression .\n",
            "May 1941 , King 12 year old grandmother Jennie died heart attack .\n",
            "event traumatic boy , watching parade parent ’ wish died .\n",
            "Distraught news , young King jumped second-story window family home , allegedly attempting suicide .\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Uq-1TTTgP4XV"
      },
      "outputs": [],
      "source": [
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    filtered_words = [lemmatizer.lemmatize(word,pos='v') for word in words if word.lower() not in stop_words]\n",
        "    sentences[i] = ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt1y3_vEQFDO",
        "outputId": "e35f08ae-a300-49e3-ad5b-7e0ffb0daf00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "middle child , Martin Jr. older sister , Willie , younger brother , Alfred .\n",
            "King child grow secure love environment .\n",
            "Martin Sr. disciplinarian , Alberta ’ gentleness easily balance father ’ strict hand .\n",
            "Although undoubtedly try , Martin Jr. ’ parent ’ shield completely racism .\n",
            "father fight racial prejudice , race suffer , also consider racism segregation affront God ’ .\n",
            "strongly discourage sense class superiority child , leave last impression Martin Jr .\n",
            "Growing Atlanta , King enter public school age 5 .\n",
            "May 1936 , baptize , event make little impression .\n",
            "May 1941 , King 12 year old grandmother Jennie die heart attack .\n",
            "event traumatic boy , watch parade parent ’ wish die .\n",
            "Distraught news , young King jump second-story window family home , allegedly attempt suicide .\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWYorFWuQg-X"
      },
      "source": [
        "##Parts of Speech Tagging\n",
        "\n",
        "\"Taj Mahal is a beautiful Monument\"\n",
        "CC - Coordinating conjunction\n",
        "\n",
        "CD - Cardinal number\n",
        "\n",
        "DT - Determiner\n",
        "\n",
        "EX - Existential \"there\" (e.g., \"there is\" ... think of it like \"there exists\")\n",
        "\n",
        "FW - Foreign word\n",
        "\n",
        "IN - Preposition or subordinating conjunction\n",
        "\n",
        "JJ - Adjective\n",
        "\n",
        "JJR - Adjective, comparative (e.g., \"bigger\")\n",
        "\n",
        "JJS - Adjective, superlative (e.g., \"biggest\")\n",
        "\n",
        "LS - List item marker\n",
        "\n",
        "MD - Modal (e.g., \"could\", \"will\")\n",
        "\n",
        "NN - Noun, singular or mass (e.g., \"desk\")\n",
        "\n",
        "NNS - Noun, plural (e.g., \"desks\")\n",
        "\n",
        "NNP - Proper noun, singular (e.g., \"Harrison\")\n",
        "\n",
        "NNPS - Proper noun, plural (e.g., \"Americans\")\n",
        "\n",
        "PDT - Predeterminer (e.g., \"all the kids\")\n",
        "\n",
        "POS - Possessive ending (e.g., \"parent's\")\n",
        "\n",
        "PRP - Personal pronoun (e.g., \"I\", \"he\", \"she\")\n",
        "\n",
        "PRP$ - Possessive pronoun (e.g., \"my\", \"his\", \"hers\")\n",
        "\n",
        "RB - Adverb (e.g., \"very\", \"silently\")\n",
        "\n",
        "RBR - Adverb, comparative (e.g., \"better\")\n",
        "\n",
        "RBS - Adverb, superlative (e.g., \"best\")\n",
        "\n",
        "RP - Particle (e.g., \"up\", \"off\")\n",
        "\n",
        "SYM - Symbol\n",
        "\n",
        "TO - to (e.g., \"to go\", \"to him\")\n",
        "\n",
        "UH - Interjection (e.g., \"uhh\", \"wow\")\n",
        "\n",
        "VB - Verb, base form (e.g., \"take\")\n",
        "\n",
        "VBD - Verb, past tense (e.g., \"took\")\n",
        "\n",
        "VBG - Verb, gerund or present participle (e.g., \"taking\")\n",
        "\n",
        "VBN - Verb, past participle (e.g., \"taken\")\n",
        "\n",
        "VBP - Verb, non-3rd person singular present (e.g., \"take\")\n",
        "\n",
        "VBZ - Verb, 3rd person singular present (e.g., \"takes\")\n",
        "\n",
        "WDT - Wh-determiner (e.g., \"which\", \"that\")\n",
        "\n",
        "WP - Wh-pronoun (e.g., \"who\", \"what\")\n",
        "\n",
        "WP$ - Possessive wh-pronoun (e.g., \"whose\")\n",
        "\n",
        "WRB - Wh-adverb (e.g., \"where\", \"when\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "eVlZAo9zQMV7"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "sentences=nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB66eLkvTx7B",
        "outputId": "3d49378a-675b-4577-83bc-438ad41ec7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8yrCGpwS4xF",
        "outputId": "d7a9cc01-a6d0-459a-83fc-7ad689aafa60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('middle', 'JJ'), ('child', 'NN'), (',', ','), ('Martin', 'NNP'), ('Jr.', 'NNP'), ('older', 'JJR'), ('sister', 'NN'), (',', ','), ('Willie', 'NNP'), (',', ','), ('younger', 'JJR'), ('brother', 'NN'), (',', ','), ('Alfred', 'NNP'), ('.', '.')]\n",
            "[('King', 'VBG'), ('children', 'NNS'), ('grew', 'VBD'), ('secure', 'NN'), ('loving', 'VBG'), ('environment', 'NN'), ('.', '.')]\n",
            "[('Martin', 'NNP'), ('Sr.', 'NNP'), ('disciplinarian', 'JJ'), (',', ','), ('Alberta', 'NNP'), ('’', 'NNP'), ('gentleness', 'NN'), ('easily', 'RB'), ('balanced', 'VBD'), ('father', 'PRP'), ('’', 'NNP'), ('strict', 'JJ'), ('hand', 'NN'), ('.', '.')]\n",
            "[('Although', 'IN'), ('undoubtedly', 'RB'), ('tried', 'VBN'), (',', ','), ('Martin', 'NNP'), ('Jr.', 'NNP'), ('’', 'NNP'), ('parents', 'NNS'), ('’', 'NNP'), ('shield', 'VBD'), ('completely', 'RB'), ('racism', 'NN'), ('.', '.')]\n",
            "[('father', 'RB'), ('fought', 'VBN'), ('racial', 'JJ'), ('prejudice', 'NN'), (',', ','), ('race', 'NN'), ('suffered', 'VBD'), (',', ','), ('also', 'RB'), ('considered', 'VBN'), ('racism', 'NN'), ('segregation', 'NN'), ('affront', 'IN'), ('God', 'NNP'), ('’', 'NNP'), ('.', '.')]\n",
            "[('strongly', 'RB'), ('discouraged', 'VBN'), ('sense', 'NN'), ('class', 'NN'), ('superiority', 'NN'), ('children', 'NNS'), (',', ','), ('left', 'VBD'), ('lasting', 'JJ'), ('impression', 'NN'), ('Martin', 'NNP'), ('Jr', 'NNP'), ('.', '.')]\n",
            "[('Growing', 'VBG'), ('Atlanta', 'NNP'), (',', ','), ('King', 'NNP'), ('entered', 'VBD'), ('public', 'JJ'), ('school', 'NN'), ('age', 'NN'), ('5', 'CD'), ('.', '.')]\n",
            "[('May', 'NNP'), ('1936', 'CD'), (',', ','), ('baptized', 'VBN'), (',', ','), ('event', 'NN'), ('made', 'VBD'), ('little', 'JJ'), ('impression', 'NN'), ('.', '.')]\n",
            "[('May', 'NNP'), ('1941', 'CD'), (',', ','), ('King', 'VBG'), ('12', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('grandmother', 'RB'), ('Jennie', 'NNP'), ('died', 'VBD'), ('heart', 'NN'), ('attack', 'NN'), ('.', '.')]\n",
            "[('event', 'NN'), ('traumatic', 'JJ'), ('boy', 'NN'), (',', ','), ('watching', 'VBG'), ('parade', 'NN'), ('parents', 'NNS'), ('’', 'VBP'), ('wishes', 'NNS'), ('died', 'VBD'), ('.', '.')]\n",
            "[('Distraught', 'NNP'), ('news', 'NN'), (',', ','), ('young', 'JJ'), ('King', 'NNP'), ('jumped', 'VBD'), ('second-story', 'JJ'), ('window', 'JJ'), ('family', 'NN'), ('home', 'NN'), (',', ','), ('allegedly', 'RB'), ('attempting', 'VBG'), ('suicide', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Process each sentence\n",
        "#We will find the pos tag\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    pos_tags = nltk.pos_tag(filtered_words)\n",
        "    print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f22bMUIpTBAg",
        "outputId": "b08b60ea-27db-4919-f854-db18948e05c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A middle child, Martin Jr. had an older sister, Willie, and a younger brother, Alfred.\n",
            "The King children grew up in a secure and loving environment.\n",
            "Martin Sr. was more the disciplinarian, while Alberta’s gentleness easily balanced out their father’s strict hand.\n",
            "Although they undoubtedly tried, Martin Jr.’s parents couldn’t shield him completely from racism.\n",
            "His father fought against racial prejudice, not just because his race suffered, but also because he considered racism and segregation to be an affront to God’s will.\n",
            "He strongly discouraged any sense of class superiority in his children, which left a lasting impression on Martin Jr.\n",
            "Growing up in Atlanta, King entered public school at age 5.\n",
            "In May 1936, he was baptized, but the event made little impression on him.\n",
            "In May 1941, King was 12 years old when his grandmother Jennie died of a heart attack.\n",
            "The event was traumatic for the boy, more so because he was out watching a parade against his parents’ wishes when she died.\n",
            "Distraught at the news, young King jumped from a second-story window at the family home, allegedly attempting suicide.\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olfwgBIdUQx5",
        "outputId": "106c5662-09c9-40c8-8a5b-106630e7132e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Great', 'NNP'), ('Wall', 'NNP'), ('of', 'IN'), ('China', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('fascinating', 'JJ'), ('Monument', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "words = nltk.word_tokenize('Great Wall of China is a fascinating Monument')\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94uLKlagWUrk"
      },
      "source": [
        "##Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J-UQfT0QWTtV",
        "outputId": "d91a2b54-6555-4577-a849-12bbe0edb983"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPerson Example:Apoorva Udupa\\nPlace Or Location Example:Udupi,India\\nDate Example:December,28-12-1996\\nTime Example: 12:45am\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "sentence=\"The Eiffel Tower, constructed starting in 1887, was the work of Gustave Eiffel, a French engineer whose firm was known for its expertise in creating metal frameworks and structures.\"\n",
        "\"\"\"\n",
        "Person Example:Apoorva Udupa\n",
        "Place Or Location Example:Udupi,India\n",
        "Date Example:December,28-12-1996\n",
        "Time Example: 12:45am\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "4gHn2ciiXTzM"
      },
      "outputs": [],
      "source": [
        "sentence=\"The Eiffel Tower, constructed starting in 1887, was the work of Gustave Eiffel, a French engineer whose firm was known for its expertise in creating metal frameworks and structures.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "VRQaTa1EYdjj"
      },
      "outputs": [],
      "source": [
        "words=nltk.word_tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OaliQACfYurG"
      },
      "outputs": [],
      "source": [
        "tag_elements=nltk.pos_tag(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMK9dt5ZFQM",
        "outputId": "b1cf1e02-ad64-47fb-8430-801216640f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2ixImFUZR0o",
        "outputId": "6a0cfdbd-5af3-46e4-fde4-bc70b0730f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Gf8yQlGXZqZK"
      },
      "outputs": [],
      "source": [
        "!export DISPLAY=:0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXoSyIzKY5lN",
        "outputId": "4afd26b5-843a-42d4-d045-9c13b92b5e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (ORGANIZATION Eiffel/NNP Tower/NNP)\n",
            "  ,/,\n",
            "  constructed/VBD\n",
            "  starting/VBG\n",
            "  in/IN\n",
            "  1887/CD\n",
            "  ,/,\n",
            "  was/VBD\n",
            "  the/DT\n",
            "  work/NN\n",
            "  of/IN\n",
            "  (ORGANIZATION Gustave/NNP Eiffel/NNP)\n",
            "  ,/,\n",
            "  a/DT\n",
            "  (GPE French/JJ)\n",
            "  engineer/NN\n",
            "  whose/WP$\n",
            "  firm/NN\n",
            "  was/VBD\n",
            "  known/VBN\n",
            "  for/IN\n",
            "  its/PRP$\n",
            "  expertise/NN\n",
            "  in/IN\n",
            "  creating/VBG\n",
            "  metal/NN\n",
            "  frameworks/NNS\n",
            "  and/CC\n",
            "  structures/NNS\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "nltk.ne_chunk(tag_elements).pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CndrvFbKE3dP"
      },
      "source": [
        "##Word2vec pretrained model by google news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QNk9AZ9aCVj",
        "outputId": "af81112d-b1c1-4db8-8506-8d872d8d43c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "V9vQltGuCUPh"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "47AeISAoCY6a"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec,KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "5Vp1KM2cClaz"
      },
      "outputs": [],
      "source": [
        "##References:https://stackoverflow.com/questions/46433778/import-googlenews-vectors-negetive300-bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGg5_1XGDBLh",
        "outputId": "1097ce1b-ddc8-4110-b6aa-7bdcb3b715b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==------------------------------------------------] 5.6% 92.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===-----------------------------------------------] 7.3% 121.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[====----------------------------------------------] 9.1% 151.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=====---------------------------------------------] 10.9% 181.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[======--------------------------------------------] 12.7% 211.3/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=======-------------------------------------------] 14.6% 241.9/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[========------------------------------------------] 16.4% 272.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=========-----------------------------------------] 18.2% 302.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==========----------------------------------------] 20.0% 332.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==========----------------------------------------] 21.8% 363.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===========---------------------------------------] 23.6% 392.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[============--------------------------------------] 25.4% 423.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=============-------------------------------------] 27.3% 453.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==============------------------------------------] 29.4% 489.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===============-----------------------------------] 31.2% 519.4/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================----------------------------------] 33.0% 549.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================---------------------------------] 34.8% 578.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================--------------------------------] 36.6% 608.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===================-------------------------------] 38.4% 638.3/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[====================------------------------------] 40.2% 668.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[====================------------------------------] 42.0% 697.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=====================-----------------------------] 43.8% 728.4/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[======================----------------------------] 45.6% 758.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=======================---------------------------] 47.4% 788.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[========================--------------------------] 49.2% 818.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=========================-------------------------] 51.0% 848.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==========================------------------------] 52.8% 878.4/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===========================-----------------------] 54.6% 907.9/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[============================----------------------] 56.4% 938.1/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=============================---------------------] 58.3% 968.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=============================---------------------] 60.0% 997.6/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==============================--------------------] 61.8% 1027.7/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===============================-------------------] 63.6% 1057.7/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================------------------] 65.3% 1086.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================-----------------] 67.0% 1114.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===================================---------------] 70.9% 1179.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[====================================--------------] 73.1% 1215.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=====================================-------------] 74.8% 1243.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[======================================------------] 76.6% 1273.0/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=======================================-----------] 78.3% 1302.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[========================================----------] 80.1% 1332.1/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[========================================----------] 81.9% 1361.4/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=========================================---------] 83.6% 1390.9/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==========================================--------] 85.4% 1420.2/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===============================================---] 95.0% 1579.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================================--] 96.7% 1608.5/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 98.5% 1637.9/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "wv=api.load('word2vec-google-news-300')\n",
        "vec_king=wv['king']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "7KHmMCPvDW-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e38e947-7c44-4dd2-b3e7-21d6ca98ed2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
              "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
              "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
              "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
              "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
              "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
              "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
              "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
              "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
              "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
              "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
              "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
              "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
              "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
              "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
              "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
              "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
              "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
              "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
              "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
              "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
              "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
              "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
              "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
              "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
              "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
              "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
              "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
              "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
              "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
              "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
              "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
              "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
              "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
              "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
              "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
              "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
              "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
              "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
              "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
              "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
              "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
              "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
              "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
              "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
              "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
              "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
              "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
              "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
              "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
              "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
              "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
              "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
              "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
              "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
              "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
              "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
              "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
              "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
              "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
              "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
              "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
              "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
              "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
              "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
              "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
              "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
              "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
              "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
              "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
              "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
              "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
              "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
              "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
              "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "vec_king"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "pS6KUY2gDfrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d364a3ec-7294-486a-a1d4-8219778f1800"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "vec_king = wv.get_vector(\"king\")\n",
        "vec_king.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "248mK36DDno_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de8205e-754f-46c5-c89e-de1d518e05d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00524902, -0.14355469, -0.06933594,  0.12353516,  0.13183594,\n",
              "       -0.08886719, -0.07128906, -0.21679688, -0.19726562,  0.05566406,\n",
              "       -0.07568359, -0.38085938,  0.10400391, -0.00081635,  0.1328125 ,\n",
              "        0.11279297,  0.07275391, -0.046875  ,  0.06591797,  0.09423828,\n",
              "        0.19042969,  0.13671875, -0.23632812, -0.11865234,  0.06542969,\n",
              "       -0.05322266, -0.30859375,  0.09179688,  0.18847656, -0.16699219,\n",
              "       -0.15625   , -0.13085938, -0.08251953,  0.21289062, -0.35546875,\n",
              "       -0.13183594,  0.09619141,  0.26367188, -0.09472656,  0.18359375,\n",
              "        0.10693359, -0.41601562,  0.26953125, -0.02770996,  0.17578125,\n",
              "       -0.11279297, -0.00411987,  0.14550781,  0.15625   ,  0.26757812,\n",
              "       -0.01794434,  0.09863281,  0.05297852, -0.03125   , -0.16308594,\n",
              "       -0.05810547, -0.34375   , -0.17285156,  0.11425781, -0.09033203,\n",
              "        0.13476562,  0.27929688, -0.04980469,  0.12988281,  0.17578125,\n",
              "       -0.22167969, -0.01190186,  0.140625  , -0.18164062,  0.11865234,\n",
              "        0.16113281,  0.21484375, -0.21191406,  0.12695312, -0.10009766,\n",
              "        0.13671875,  0.12695312,  0.01531982,  0.10449219, -0.02783203,\n",
              "       -0.06030273,  0.0222168 ,  0.18164062, -0.06738281,  0.04907227,\n",
              "        0.15429688, -0.25      ,  0.13964844,  0.29492188,  0.10644531,\n",
              "        0.3359375 , -0.22265625, -0.125     , -0.05297852,  0.19238281,\n",
              "        0.06835938,  0.06982422, -0.05200195,  0.14453125,  0.00448608,\n",
              "       -0.01013184, -0.1484375 ,  0.21777344, -0.1953125 , -0.390625  ,\n",
              "        0.07763672, -0.57421875, -0.07910156, -0.04052734, -0.1875    ,\n",
              "        0.25390625,  0.15722656,  0.125     ,  0.140625  ,  0.20117188,\n",
              "       -0.05859375,  0.16894531, -0.28125   ,  0.171875  ,  0.19140625,\n",
              "        0.12109375, -0.15039062, -0.00695801, -0.23730469,  0.13964844,\n",
              "       -0.00836182, -0.04711914,  0.14648438, -0.05688477,  0.10205078,\n",
              "        0.08447266,  0.21191406, -0.01831055,  0.50390625, -0.04858398,\n",
              "        0.22167969, -0.25585938,  0.03417969,  0.15820312, -0.03369141,\n",
              "        0.06738281, -0.25195312,  0.04614258, -0.07275391,  0.07958984,\n",
              "        0.04223633, -0.00128937,  0.20214844, -0.13085938, -0.06030273,\n",
              "        0.0378418 ,  0.13574219,  0.11181641, -0.24609375, -0.23925781,\n",
              "       -0.23632812, -0.04321289, -0.02905273,  0.23535156, -0.00390625,\n",
              "       -0.05029297,  0.18457031,  0.50390625, -0.00668335, -0.03466797,\n",
              "       -0.07568359,  0.06152344, -0.31445312, -0.03759766,  0.23632812,\n",
              "       -0.12792969,  0.15429688,  0.296875  ,  0.02709961, -0.17089844,\n",
              "       -0.22460938,  0.00241089,  0.10595703, -0.03320312,  0.0145874 ,\n",
              "       -0.21582031,  0.24707031, -0.07421875, -0.10205078,  0.16894531,\n",
              "       -0.05029297,  0.20800781, -0.03857422, -0.22265625,  0.27539062,\n",
              "       -0.05957031, -0.01757812,  0.01794434,  0.08886719,  0.12890625,\n",
              "        0.18261719,  0.14453125,  0.10400391, -0.1328125 , -0.32617188,\n",
              "        0.00386047, -0.11376953, -0.05053711, -0.13085938,  0.02209473,\n",
              "       -0.14648438,  0.10742188,  0.23046875,  0.15234375,  0.22753906,\n",
              "        0.04833984,  0.06787109, -0.06787109, -0.2578125 ,  0.11230469,\n",
              "        0.00363159, -0.12011719, -0.21289062,  0.11230469,  0.12158203,\n",
              "        0.06835938,  0.04907227,  0.2734375 , -0.00302124, -0.00378418,\n",
              "        0.00193787,  0.1875    , -0.29101562,  0.09033203,  0.26367188,\n",
              "       -0.25585938, -0.28710938, -0.40820312,  0.10546875,  0.39648438,\n",
              "       -0.07275391, -0.04321289, -0.06347656, -0.00060272, -0.11523438,\n",
              "        0.31445312, -0.22265625,  0.13574219, -0.01965332,  0.15332031,\n",
              "        0.00360107, -0.12011719,  0.06494141,  0.16210938, -0.16699219,\n",
              "        0.03271484, -0.00350952,  0.18847656,  0.19335938,  0.1328125 ,\n",
              "        0.06787109, -0.34179688, -0.08349609, -0.29492188, -0.02099609,\n",
              "        0.08886719,  0.32421875, -0.36914062, -0.0859375 , -0.04956055,\n",
              "        0.13183594,  0.04418945,  0.359375  ,  0.21484375,  0.265625  ,\n",
              "       -0.2734375 ,  0.23535156,  0.11425781,  0.08789062,  0.1875    ,\n",
              "       -0.33203125,  0.15136719, -0.03613281, -0.11914062,  0.27734375,\n",
              "        0.10839844, -0.07275391,  0.23242188,  0.00219727,  0.23828125,\n",
              "       -0.24902344, -0.12353516, -0.15917969, -0.00601196,  0.14550781,\n",
              "       -0.00460815, -0.22558594, -0.37890625, -0.37695312, -0.08251953,\n",
              "       -0.04125977,  0.16796875, -0.046875  ,  0.16308594,  0.15429688],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "wv['queen']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ttFWnSduDvC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41aad974-d49a-49f3-a798-032354ce4c31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queens', 0.739944338798523),\n",
              " ('princess', 0.7070532441139221),\n",
              " ('king', 0.6510956883430481),\n",
              " ('monarch', 0.6383602023124695),\n",
              " ('very_pampered_McElhatton', 0.6357026696205139),\n",
              " ('Queen', 0.6163407564163208),\n",
              " ('NYC_anglophiles_aflutter', 0.6060680150985718),\n",
              " ('Queen_Consort', 0.5923796892166138),\n",
              " ('princesses', 0.5908074975013733),\n",
              " ('royal', 0.5637185573577881)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "wv.most_similar('queen')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "D155yxr3D3XZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbc1330-bc2f-48c3-b2dd-0054712db9ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('saddening', 0.7273085713386536),\n",
              " ('Sad', 0.6610826849937439),\n",
              " ('saddened', 0.6604382395744324),\n",
              " ('heartbreaking', 0.6573508381843567),\n",
              " ('disheartening', 0.6507317423820496),\n",
              " ('Meny_Friedman', 0.6487058401107788),\n",
              " ('parishioner_Pat_Patello', 0.6475860476493835),\n",
              " ('saddens_me', 0.6407119035720825),\n",
              " ('distressing', 0.6399092674255371),\n",
              " ('reminders_bobbing', 0.6357713341712952)]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "wv.most_similar('sad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "VJXujSPwD73o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f4ecf6-796a-496b-c6e9-fc8108f50005"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510956"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "wv.similarity(\"king\",\"queen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Mz-9diSPEI6T"
      },
      "outputs": [],
      "source": [
        "vec=wv['king']-wv['man']+wv['woman']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "UFnYjdsEEgfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4828c6c3-191a-4a5c-a650-0cf7388a26d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.29687500e-02, -1.78222656e-01, -1.29089355e-01,  1.15234375e-01,\n",
              "        2.68554688e-03, -1.02294922e-01,  1.95800781e-01, -1.79504395e-01,\n",
              "        1.95312500e-02,  4.09919739e-01, -3.68164062e-01, -3.96484375e-01,\n",
              "       -1.56738281e-01,  1.46484375e-03, -9.30175781e-02, -1.16455078e-01,\n",
              "       -5.51757812e-02, -1.07574463e-01,  7.91015625e-02,  1.98974609e-01,\n",
              "        2.38525391e-01,  6.34002686e-02, -2.17285156e-02,  0.00000000e+00,\n",
              "        4.72412109e-02, -2.17773438e-01, -3.44726562e-01,  6.37207031e-02,\n",
              "        3.16406250e-01, -1.97631836e-01,  8.59375000e-02, -8.11767578e-02,\n",
              "       -3.71093750e-02,  3.15551758e-01, -3.41796875e-01, -4.68750000e-02,\n",
              "        9.76562500e-02,  8.39843750e-02, -9.71679688e-02,  5.17578125e-02,\n",
              "       -5.00488281e-02, -2.20947266e-01,  2.29492188e-01,  1.26403809e-01,\n",
              "        2.49023438e-01,  2.09960938e-02, -1.09863281e-01,  5.81054688e-02,\n",
              "       -3.35693359e-02,  1.29577637e-01,  2.41699219e-02,  3.48129272e-02,\n",
              "       -2.60009766e-01,  2.42309570e-01, -3.21777344e-01,  1.45416260e-02,\n",
              "       -1.59179688e-01, -8.37402344e-02,  1.65039062e-01,  1.58691406e-03,\n",
              "        3.09570312e-01,  3.16406250e-01,  7.38525391e-03,  2.41210938e-01,\n",
              "        4.90722656e-02, -9.86328125e-02,  2.90527344e-02,  1.49414062e-01,\n",
              "       -4.83398438e-02,  2.35595703e-01,  2.21191406e-01,  1.25488281e-01,\n",
              "       -1.38671875e-01,  1.54296875e-01,  7.18994141e-02,  1.29882812e-01,\n",
              "       -1.05712891e-01,  6.00585938e-02,  3.14697266e-01,  1.09619141e-01,\n",
              "        8.49609375e-02,  7.71484375e-02, -2.17285156e-02,  6.11572266e-02,\n",
              "       -1.89941406e-01,  2.07519531e-01, -1.63085938e-01,  1.13525391e-01,\n",
              "        2.01171875e-01,  6.06689453e-02,  1.27929688e-01, -3.11279297e-01,\n",
              "       -2.80151367e-01, -1.55883789e-01,  4.15039062e-02,  9.87854004e-02,\n",
              "        1.69555664e-01, -3.49121094e-02,  2.08496094e-01, -9.89990234e-02,\n",
              "        4.39453125e-03, -7.27539062e-02, -4.24804688e-02, -4.09179688e-01,\n",
              "       -2.76367188e-01,  1.64062500e-01, -5.57617188e-01, -2.02199936e-01,\n",
              "        2.12158203e-01, -9.81445312e-02,  2.30773926e-01,  2.75878906e-01,\n",
              "        1.68092728e-01, -4.50439453e-02,  1.71615601e-01, -3.77075195e-01,\n",
              "       -3.52478027e-03, -3.01513672e-01,  1.74224854e-01,  3.30078125e-01,\n",
              "        2.00683594e-01,  1.17736816e-01, -1.37695312e-01, -1.07421875e-01,\n",
              "        8.61816406e-02,  1.06445312e-01,  1.44531250e-01,  3.05175781e-03,\n",
              "        1.80664062e-02,  3.73535156e-02,  7.32421875e-03,  1.32812500e-01,\n",
              "        9.61914062e-02,  3.35998535e-01,  1.81152344e-01,  2.40905762e-01,\n",
              "       -8.49609375e-02, -1.10107422e-01,  2.11914062e-01,  5.85937500e-03,\n",
              "        1.62109375e-01, -4.15527344e-01,  1.39160156e-01,  1.01562500e-01,\n",
              "        1.44531250e-01, -1.09375000e-01,  4.88281250e-02,  6.15234375e-02,\n",
              "       -1.69921875e-01,  3.28369141e-02,  5.56640625e-02,  1.47460938e-01,\n",
              "       -2.24609375e-02, -2.73925781e-01, -2.81982422e-01, -1.39160156e-01,\n",
              "       -1.81884766e-01,  9.33532715e-02,  1.21093750e-01, -5.37109375e-03,\n",
              "       -1.87500000e-01,  3.05175781e-04,  5.52734375e-01, -9.71679688e-02,\n",
              "       -1.81640625e-01, -1.51855469e-01,  7.76367188e-02, -2.38281250e-01,\n",
              "       -2.63977051e-02,  2.25555420e-01, -3.02734375e-01,  1.34765625e-01,\n",
              "        3.23242188e-01,  1.25976562e-01,  3.51562500e-02, -2.04345703e-01,\n",
              "        2.96142578e-01,  1.03149414e-01, -4.76074219e-03,  1.69189453e-01,\n",
              "       -3.50585938e-01,  2.46887207e-02, -3.90502930e-01, -2.70507812e-01,\n",
              "        1.85241699e-02,  1.04492188e-01,  2.84179688e-01,  1.35009766e-01,\n",
              "       -5.95703125e-02,  1.88232422e-01,  8.88214111e-02,  3.24707031e-02,\n",
              "       -8.98437500e-02,  5.45043945e-02,  5.65185547e-02,  1.56860352e-01,\n",
              "       -9.70458984e-03, -7.08007812e-02,  5.71289062e-02, -3.08837891e-01,\n",
              "       -1.91894531e-01,  4.83398438e-02,  5.22460938e-02, -1.59667969e-01,\n",
              "       -4.49218750e-02, -7.37304688e-02,  5.51757812e-02,  2.12402344e-01,\n",
              "        2.05322266e-01, -2.73437500e-02,  7.86132812e-02,  3.19091797e-01,\n",
              "       -1.56982422e-01, -3.92822266e-01,  4.00390625e-02,  9.93652344e-02,\n",
              "       -1.97372437e-02, -8.25195312e-02,  2.53906250e-02,  3.10668945e-02,\n",
              "       -3.63769531e-02,  1.48925781e-02,  2.20703125e-01, -5.98144531e-02,\n",
              "        6.15234375e-02, -7.14111328e-02, -4.00390625e-02, -1.03515625e-01,\n",
              "        9.22851562e-02,  2.71789551e-01, -2.30224609e-01, -2.62695312e-01,\n",
              "       -5.61523438e-01,  1.38549805e-02,  1.09863281e-01,  7.22656250e-02,\n",
              "        4.58984375e-02, -3.31802368e-02, -8.03833008e-02, -6.10351562e-03,\n",
              "        2.09960938e-01, -3.86840820e-01,  1.44645691e-01,  8.05664062e-02,\n",
              "        2.96264648e-01, -1.17187500e-02, -2.34680176e-01,  1.32019043e-01,\n",
              "        2.53906250e-01, -2.46826172e-01,  1.03759766e-01,  1.14013672e-01,\n",
              "        1.71875000e-01, -5.61523438e-03,  2.05078125e-01,  6.34765625e-02,\n",
              "       -4.51293945e-01, -2.26562500e-01, -1.03027344e-01, -1.31469727e-01,\n",
              "        3.75976562e-02,  2.70996094e-01, -2.39257812e-01,  3.80859375e-02,\n",
              "       -3.90625000e-02, -9.42382812e-02,  8.30078125e-03,  7.03125000e-02,\n",
              "        2.75390625e-01,  3.31542969e-01, -1.07421875e-02,  3.72192383e-01,\n",
              "       -1.24511719e-01,  1.94335938e-01, -1.35620117e-01, -3.09570312e-01,\n",
              "       -2.36328125e-01, -1.26953125e-02, -2.76855469e-01,  1.57714844e-01,\n",
              "        3.07617188e-01, -2.32910156e-01,  3.25439453e-01,  1.36718750e-02,\n",
              "        1.99462891e-01, -2.61840820e-02, -8.08105469e-02, -7.50732422e-02,\n",
              "       -4.11109924e-02,  1.95556641e-01, -5.64270020e-02, -2.79296875e-01,\n",
              "       -2.75390625e-01, -4.04296875e-01, -1.75781250e-02, -5.85937500e-03,\n",
              "       -7.71484375e-02,  1.33789062e-01,  2.36816406e-01,  2.01538086e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "gqztNK1qEpIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dedb444-b1c3-4c56-eca8-c1ccd920cdce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.8449392318725586),\n",
              " ('queen', 0.7300517559051514),\n",
              " ('monarch', 0.645466148853302),\n",
              " ('princess', 0.6156251430511475),\n",
              " ('crown_prince', 0.5818676352500916),\n",
              " ('prince', 0.5777117609977722),\n",
              " ('kings', 0.5613663792610168),\n",
              " ('sultan', 0.5376775860786438),\n",
              " ('Queen_Consort', 0.5344247817993164),\n",
              " ('queens', 0.5289887189865112)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "wv.most_similar([vec])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujVnMJfIWBjz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}